# -*- coding: utf-8 -*-
"""Countries of the World.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zoReM_SIswomhVFf6shn6LtpLFgiew5N
"""

# Instalaci√≥n de Beautiful Soup
!pip install beautifulsoup4
from bs4 import BeautifulSoup as bs

# Instalacion de Requests
!pip install requests
import requests

# Elegir un sitio web del que queremos extraer datos,
from bs4 import BeautifulSoup
main_url = 'https://www.scrapethissite.com/pages/simple/'
res = requests.get(main_url)
print(res)

html_obtenido = res.text

# 2. "Parsear" ese HTML
soup = BeautifulSoup(html_obtenido, "html.parser")

'''
<div class="col-md-4 country">
    <h3 class="country-name">
        <i class="flag-icon flag-icon-ad"></i>
        Andorra
    </h3>
    <div class="country-info">
        <strong>Capital:</strong> <span class="country-capital">Andorra la Vella</span><br>
        <strong>Population:</strong> <span class="country-population">84000</span><br>
        <strong>Area (km<sup>2</sup>):</strong> <span class="country-area">468.0</span><br>
    </div>
</div>
'''
import pandas as pd
divs = soup.find_all('div', class_ = "col-md-4 country")

country = []
capital = []
population = []
area = []

scraped_data = []

for div in divs:
  country.append(div.h3.get_text(strip=True))
  capital_text = div.find("span", class_ = "country-capital").text
  if capital_text == 'None':
    capital_text = 'Sin capital'
  capital.append(capital_text)
  population.append(div.find("span", class_ = "country-population").text)
  area.append(div.find("span", class_ = "country-area").text)

  #print(f'{country}, {capital}, {population}, {area}')

scraped_data = pd.DataFrame({
    'Country': country,
    'Capital': capital,
    'Population': population,
    'Area (km2)': area,
})

scraped_data.head(10)

# Exportar df a csv
scraped_data.to_csv(
    'countries.csv',
    index=True, sep=';',
    encoding='utf-8'
)