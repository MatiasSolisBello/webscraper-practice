# -*- coding: utf-8 -*-
"""Hockey Teams.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14cVY_7M1MnNydUBjQRaxUNit1TkSFQ--
"""

# Instalaci√≥n de Beautiful Soup
!pip install beautifulsoup4
from bs4 import BeautifulSoup as bs

# Instalacion de Requests
!pip install requests
import requests

# Elegir un sitio web del que queremos extraer datos,
from bs4 import BeautifulSoup
main_url = 'https://www.scrapethissite.com/pages/forms/'
res = requests.get(main_url)
print(res)

html_obtenido = res.text

# 2. "Parsear" ese HTML
soup = BeautifulSoup(html_obtenido, "html.parser")

import pandas as pd


"""
<table>
    <tr class="team">
        <td class="name">Boston Bruins</td>
        <td class="year">1990</td>
        <td class="wins">44</td>
        <td class="losses">24</td>
        <td class="ot-losses"></td>
        <td class="pct text-success">0.55</td>
        <td class="gf">299</td>
        <td class="ga">264</td>
        <td class="diff text-success">35</td>
    </tr>

    <tr class="team">
        ...
    </tr>

    <tr class="team">
        ...
    </tr>
</table>

"""
print('main_url: ', main_url)
data = []
max_pages = 24



for page_num in range(1, max_pages + 1):
    url = f'{main_url}?page_num/{page_num}'
    response = requests.get(url)
    print('url: ', url, response)

    res = requests.get(url)
    html_obtenido = res.text
    soup = BeautifulSoup(html_obtenido, "html.parser")

    rows = soup.find_all('tr', class_='team')

    for row in rows:
        cols = row.find_all('td')
        cols = [col.text.strip() for col in cols]
        data.append(cols)


# Convertir la lista en un DataFrame de pandas
df = pd.DataFrame(data,
                  columns=['Team Name', 'Year', 'Wins', 'Losses', 'OT Losses', 'Pct', 'GF', 'GA', 'Diff']
)

# Mostrar el DataFrame
df.tail(10)

df.to_csv(
    'hockey_teams_data.csv',
    index=False, sep=';',
    encoding='utf-8'
)